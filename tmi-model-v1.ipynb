{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1.Import Data"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"from pyspark.context import SparkContext\nfrom pyspark.sql import HiveContext, SparkSession\n\n\n# Creating a SparkContext is a must\nsc = SparkContext(appName=\"<app_name\")\n# Optional creation of a HiveContext\nsql_context = HiveContext(sc)\n# Optional creation of a SparkSession\nspark = SparkSession(sc)\nspark = (SparkSession.builder.enableHiveSupport().getOrCreate())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"spark.sparkContext.stop() \nspark = SparkSession.builder.config('spark.kryoserializer.buffer.max', '1g').config('spark.driver.maxResultSize', '25g').getOrCreate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.offline as py#visualization\npy.init_notebook_mode(connected=True)#visualization\nimport plotly.graph_objs as go#visualization\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"context= spark.sql(\"use anp_catdidai1_sandbox\")\nspark_df = spark.sql (\"select * from anp_catdidai1_sandbox.tmi_data_all_in_a\")\ndf_1 = spark_df.toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"context= spark.sql(\"use anp_catdidai1_sandbox\")\nspark_df = spark.sql (\"select * from anp_catdidai1_sandbox.tmi_data_all_in_b\")\ndf_2 = spark_df.toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"context= spark.sql(\"use anp_catdidai1_sandbox\")\nspark_df = spark.sql (\"select * from anp_catdidai1_sandbox.tmi_data_all_in_c\")\ndf_3 = spark_df.toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"context= spark.sql(\"use anp_catdidai1_sandbox\")\nspark_df = spark.sql (\"select * from anp_catdidai1_sandbox.tmi_data_all_in_d\")\ndf_4 = spark_df.toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"context= spark.sql(\"use anp_catdidai1_sandbox\")\nspark_df = spark.sql (\"select * from anp_catdidai1_sandbox.tmi_data_all_in_e\")\ndf_5 = spark_df.toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tmi_data=pd.concat([df_1,df_2,df_3,df_4,df_5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.1Data Overview & Manipulation"},{"metadata":{"trusted":false},"cell_type":"code","source":"#sort data and display the first 5 rows of the dataset\ntmi_data=tmi_data.sort_values(by=['cust_id'])\ntmi_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tmi_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.2.1 Data Manipulation - Converting variables into the right type"},{"metadata":{"trusted":false},"cell_type":"code","source":"#convert to float type\nconvert_cols = [ 'cust_mnyin_prtbal_am', 'sum_tran_am_jan', 'sum_tran_am_feb', 'sum_tran_am_mar', 'sum_tran_am_apr', \n                'sum_tran_am_may', 'sum_tran_am_jun', 'sum_tran_am_jul', 'sum_tran_am_aug', 'sum_tran_am_sep', \n                'sum_tran_am_oct', 'sum_tran_am_nov', 'sum_tran_am_dec', 'sum_tran_am_monday', 'sum_tran_am_tuesday', \n                'sum_tran_am_wednesday', 'sum_tran_am_thursday', 'sum_tran_am_friday', 'sum_tran_am_saturday', \n                'sum_tran_am_sunday', 'sum_tran_am_spring', 'sum_tran_am_summer', 'sum_tran_am_fall', 'sum_tran_am_winter', \n                'sum_tran_am_xmas', 'sum_tran_am_last_3mo', 'sum_tran_am_last_6mo', 'sum_tran_am_last_12mo', \n                'sum_tran_am_last_24mo',  'sum_tran_am_in_3yr']\n\nfor i in convert_cols : \n    tmi_data[i]  = tmi_data[i].astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.2.2 Data Manipulation - Missing value imputation"},{"metadata":{"trusted":false},"cell_type":"code","source":"## Null Counting Fucntion\ndef null_values(df):\n    \n    sum_null = df.isnull().sum()\n    total = df.isnull().count()\n    percent_nullvalues = 100* sum_null / total \n    df_null = pd.DataFrame()\n    df_null['Total'] = total\n    df_null['Null_Count'] = sum_null\n    df_null['Percent'] = round(percent_nullvalues,2)\n    df_null = df_null.sort_values(by='Null_Count',ascending = False)\n    df_null = df_null[df_null.Null_Count > 0]\n    \n    return(df_null)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Find missing value percentage (before imputation)\nnull_values(tmi_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We divided the variables that contains NA into three major groups.\n\nGroup 1 -- demograhics -- such as age, tenure, beacon score and etc. Instead of deleting all NA entries(this may cause information loss), I have categorized NAs into Unknowns. For example, if the age is NA, then it will be grouped into Age_Group as 'Unknown'. We keep original data to calculate statistical summary in later step. \n\nGroup 2 -- transactional -- such as num_travel_tran_jan, sum_tran_am_jan and etc. Most of NAs are coming from customers who have never use TD to book travel in the past three years. Logically speaking, if a customer have never book travel with TD, the number of travel transactions in January should be zero. Therefore, I imputed all the NAs that follow into this group as '0'. \n\nGroup 3 -- transactional -- such as num_day_since_last_book, avg_day_between_travel and etc. These variables calculate the recency, for example, num_day_since_last_book calculates how many days it has been since last travel booking, and avg_day_between_travel simply calculate the average of the time interval between each travel booking. NAs are coming from those who have never book travel with TD, or booked only once with TD (therefore, cannot calculate the average), or booked less than three times. Therefore, I imputed all the NAs into 1096 (365* 3 + 1 = 1096) to represent the last time of booking is three years ago/a very long time ago. \n\nPlease note, this imputation method makes sense logically, however, with this imputation, our datasets is heavily skewed. "},{"metadata":{"trusted":false},"cell_type":"code","source":"#NA imputation based on assumptions above\ntmi_data.update(tmi_data[['num_trav_tran_jan', 'num_trav_tran_feb', 'num_trav_tran_mar', 'num_trav_tran_apr', \n                          'num_trav_tran_may', 'num_trav_tran_jun', 'num_trav_tran_jul', 'num_trav_tran_aug', \n                          'num_trav_tran_sep', 'num_trav_tran_oct', 'num_trav_tran_nov', 'num_trav_tran_dec', \n                          'num_trav_tran_monday', 'num_trav_tran_tuesday', 'num_trav_tran_wednesday', 'num_trav_tran_thursday', \n                          'num_trav_tran_friday', 'num_trav_tran_saturday', 'num_trav_tran_sunday', 'num_trav_tran_spring',\n                          'num_trav_tran_summer', 'num_trav_tran_fall', 'num_trav_tran_winter', 'num_trav_tran_xmas', \n                          'num_trav_tran_last_3mo', 'num_trav_tran_last_6mo', 'num_trav_tran_last_12mo', \n                          'num_trav_tran_last_24mo', 'sum_tran_am_jan', 'sum_tran_am_feb', 'sum_tran_am_mar', \n                          'sum_tran_am_apr', 'sum_tran_am_may', 'sum_tran_am_jun', 'sum_tran_am_jul', 'sum_tran_am_aug', \n                          'sum_tran_am_sep', 'sum_tran_am_oct', 'sum_tran_am_nov', 'sum_tran_am_dec', 'sum_tran_am_monday', \n                          'sum_tran_am_tuesday', 'sum_tran_am_wednesday', 'sum_tran_am_thursday', 'sum_tran_am_friday', \n                          'sum_tran_am_saturday', 'sum_tran_am_sunday', 'sum_tran_am_spring', 'sum_tran_am_summer', \n                          'sum_tran_am_fall', 'sum_tran_am_winter', 'sum_tran_am_xmas', 'sum_tran_am_last_3mo', \n                          'sum_tran_am_last_6mo', 'sum_tran_am_last_12mo', 'sum_tran_am_last_24mo', 'num_trav_tran_in_3yr', \n                          'sum_tran_am_in_3yr']].fillna(0))\n\ntmi_data.update(tmi_data[['num_day_since_last_book', 'num_day_since_2nd_last_book', \n                          'num_day_since_3rd_last_book', 'avg_day_between_travel']].fillna(1096))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Drop original columns that contains NAs, as we have binned the data into multiple buckets (eg. age --> age_group) \nto_drop = ['id', 'beacon_sc', 'cust_mnyin_prtbal_am', 'customer_age','total_hhold_member_ct','customer_tenure', 'num_td_rewards_visa_card']\n\ntmi_data_copy=tmi_data.drop(columns=to_drop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# For now, we have imputed all the NAs. \nprint (\"\\nMissing values :  \", tmi_data_copy.isnull().sum().values.sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"This section is under construction."},{"metadata":{},"cell_type":"markdown","source":"# 2.1 Travel Booking in Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"trav_book_next3mo     = tmi_data_copy[tmi_data_copy[\"target_istravel\"] == 1]\nno_trav_book_next3mo = tmi_data_copy[tmi_data_copy[\"target_istravel\"] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Id_col     = ['cust_id']\ntarget_col = ['target_istravel']\ncat_cols   = ['is_staff', 'gender', 'age_group', 'province', 'customer_tenure', 'ins_life_health_solict_in',\n              'beacon_credit_score', 'total_hhold_member_ct', 'income_group']\nnum_cols   = [x for x in tmi_data_copy.columns if x not in cat_cols + target_col + Id_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#labels\nlab = tmi_data_copy[\"target_istravel\"].value_counts().keys().tolist()\n#values\nval = tmi_data_copy[\"target_istravel\"].value_counts().values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"trace = go.Pie(labels = lab ,\n               values = val ,\n               marker = dict(colors =  [ 'royalblue' ,'lime'],\n                             line = dict(color = \"white\",\n                                         width =  1.3)\n                            ),\n               rotation = 90,\n               hoverinfo = \"label+value+text\",\n               hole = .5\n              )\nlayout = go.Layout(dict(title = \"Customer Travel Booking in Next 3 Months\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                       )\n                  )\n\ndata = [trace]\nfig = go.Figure(data = data,layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.2 Variable Distribution in Travel Booking"},{"metadata":{"trusted":false},"cell_type":"code","source":"def plot_pie(column) :\n    \n    trace1 = go.Pie(values  = trav_book_next3mo[column].value_counts().values.tolist(),\n                    labels  = trav_book_next3mo[column].value_counts().keys().tolist(),\n                    hoverinfo = \"label+percent+name\",\n                    domain  = dict(x = [0,.48]),\n                    name    = \"Travel Booking Customers\",\n                    marker  = dict(line = dict(width = 2,\n                                               color = \"rgb(243,243,243)\")\n                                  ),\n                    hole    = .6\n                   )\n    trace2 = go.Pie(values  = no_trav_book_next3mo[column].value_counts().values.tolist(),\n                    labels  = no_trav_book_next3mo[column].value_counts().keys().tolist(),\n                    hoverinfo = \"label+percent+name\",\n                    marker  = dict(line = dict(width = 2,\n                                               color = \"rgb(243,243,243)\")\n                                  ),\n                    domain  = dict(x = [.52,1]),\n                    hole    = .6,\n                    name    = \"No Travel Booking Customers\" \n                   )\n\n\n    layout = go.Layout(dict(title = column + \" distribution in travel booking \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            annotations = [dict(text = \"Travel Booking Customers\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .15, y = .5),\n                                           dict(text = \"No Travel Booking Customers\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .88,y = .5\n                                               )\n                                          ]\n                           )\n                      )\n    data = [trace1,trace2]\n    fig  = go.Figure(data = data,layout = layout)\n    py.iplot(fig)\n\n\n#function  for histogram for travel booking \ndef histogram(column) :\n    trace1 = go.Histogram(x  = trav_book_next3mo[column],\n                          histnorm= \"percent\",\n                          name = \"Travel Booking Customers\",\n                          marker = dict(line = dict(width = .5,\n                                                    color = \"black\"\n                                                    )\n                                        ),\n                         opacity = .9 \n                         ) \n    \n    trace2 = go.Histogram(x  = no_trav_book_next3mo[column],\n                          histnorm = \"percent\",\n                          name = \"No Travel Booking Customers\",\n                          marker = dict(line = dict(width = .5,\n                                              color = \"black\"\n                                             )\n                                 ),\n                          opacity = .9\n                         )\n    \n    data = [trace1,trace2]\n    layout = go.Layout(dict(title =column + \" distribution in travel booking \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                             title = column,\n                                             zerolinewidth=1,\n                                             ticklen=5,\n                                             gridwidth=2\n                                            ),\n                            yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                             title = \"percent\",\n                                             zerolinewidth=1,\n                                             ticklen=5,\n                                             gridwidth=2\n                                            ),\n                           )\n                      )\n    fig  = go.Figure(data=data,layout=layout)\n    \n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#for all categorical columns plot pie\ncat_cols_1   = ['is_staff', 'gender', 'province', 'ins_life_health_solict_in',\n              'beacon_credit_score', 'total_hhold_member_ct', 'income_group']\nfor i in cat_cols_1 :\n    plot_pie(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#customer travel booking in tenure groups\nag_tb  =  trav_book_next3mo[\"age_group\"].value_counts().reset_index()\nag_tb.columns  = [\"age_group\",\"count\"]\nag_ntb =  no_trav_book_next3mo[\"age_group\"].value_counts().reset_index()\nag_ntb.columns = [\"age_group\",\"count\"]\n\n#bar - travel booking\ntrace1 = go.Bar(x = ag_tb[\"age_group\"]  , y = ag_tb[\"count\"],\n                name = \"Travel Booking Customers\",\n                marker = dict(line = dict(width = .5,color = \"black\")),\n                opacity = .9)\n\n#bar - no travel booking\ntrace2 = go.Bar(x = ag_ntb[\"age_group\"] , y = ag_ntb[\"count\"],\n                name = \"No Travel Booking Customers\",\n                marker = dict(line = dict(width = .5,color = \"black\")),\n                opacity = .9)\n\nlayout = go.Layout(dict(title = \"Travel Booking in Age Groups\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"Age Group\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"Count\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                       )\n                  )\ndata = [trace1,trace2]\nfig  = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#customer travel booking in tenure groups\nct_tb  =  trav_book_next3mo[\"customer_tenure\"].value_counts().reset_index()\nct_tb.columns  = [\"customer_tenure\",\"count\"]\nct_ntb =  no_trav_book_next3mo[\"customer_tenure\"].value_counts().reset_index()\nct_ntb.columns = [\"customer_tenure\",\"count\"]\n\n#bar - travel booking\ntrace1 = go.Bar(x = ct_tb[\"customer_tenure\"]  , y = ct_tb[\"count\"],\n                name = \"Travel Booking Customers\",\n                marker = dict(line = dict(width = .5,color = \"black\")),\n                opacity = .9)\n\n#bar - no travel booking\ntrace2 = go.Bar(x = ct_ntb[\"customer_tenure\"] , y = ct_ntb[\"count\"],\n                name = \"No Travel Booking Customers\",\n                marker = dict(line = dict(width = .5,color = \"black\")),\n                opacity = .9)\n\nlayout = go.Layout(dict(title = \"Travel Booking in Customer Tenure\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"Customer Tenure Group\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"Count\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                       )\n                  )\ndata = [trace1,trace2]\nfig  = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#for all numerical columns plot histogram   \nnum_cols_1 = ['num_acct', 'num_money_builder_account', 'num_investment_builder_account', 'num_selectline_line', \n              'num_td_rsp_plan', 'num_usd_daily_interest_chequing_account', 'num_td_first_class_travel_visa_infinite', \n              'num_td_aeroplan_visa_infinite', 'num_td_cash_back_visa', 'num_td_cash_back_visa_infinite', \n              'num_td_business_travel', 'num_td_emerald_flex_rate_visa']\n              \n              #'num_day_since_last_book',\n              #'num_day_since_2nd_last_book', 'num_day_since_3rd_last_book', 'avg_day_between_travel', 'num_trav_in_3yr', \n              #'sum_trav_tran_am_in_3yr', 'num_trav_in_last_3mo', 'sum_trav_tran_am_in_last_3mo', 'num_trav_in_last_6mo', \n              #'sum_trav_tran_am_in_last_6mo', 'num_trav_in_last_12mo', 'sum_trav_tran_am_in_last_12mo', 'num_trav_in_last_24mo',\n              #'sum_trav_tran_am_in_last_24mo', 'num_trav_around_xmas', 'sum_trav_tran_am_around_xmas', 'num_trav_in_spring', \n              #'sum_trav_tran_am_in_spring', 'num_trav_in_summer', 'sum_trav_tran_am_in_summer', 'num_trav_in_fall', \n              #'sum_trav_tran_am_in_fall', 'num_trav_in_winter', 'sum_trav_tran_am_in_winter', 'target_istravel']\nfor i in num_cols_1 :\n    histogram(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Statistical Summary"},{"metadata":{"trusted":false},"cell_type":"code","source":"summary = (tmi_data[[i for i in tmi_data.columns if i not in Id_col + Id2_col]].\n           describe().transpose().reset_index())\n\nsummary = summary.rename(columns = {\"index\" : \"feature\"})\nsummary = np.around(summary,3)\n\nval_lst = [summary['feature'], summary['count'],\n           summary['mean'],summary['std'],\n           summary['min'], summary['25%'],\n           summary['50%'], summary['75%'], summary['max']]\n\ntrace  = go.Table(header = dict(values = summary.columns.tolist(),\n                                line = dict(color = ['#506784']),\n                                fill = dict(color = ['#119DFF']),\n                               ),\n                  cells  = dict(values = val_lst,\n                                line = dict(color = ['#506784']),\n                                fill = dict(color = [\"lightgrey\",'#F5F8FF'])\n                               ),\n                  columnwidth = [200,60,100,100,60,60,80,80,80])\nlayout = go.Layout(dict(title = \"Variable Summary\"))\nfigure = go.Figure(data=[trace],layout=layout)\npy.iplot(figure)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Data Preprocessing"},{"metadata":{"trusted":false},"cell_type":"code","source":"#customer id col\nId_col     = ['cust_id']\n\n\n#target variable col\ntarget_col = ['target_istravel']\n#categorical columns\ncat_cols   = ['is_staff', 'gender_ds', 'age_group', 'contry_region_ds',\n              'tenure_group', 'ins_life_health_solict_in', 'beacon_score_group', 'family_size_group', 'income_group']\n    \n#numerical columns\nnum_cols   = [x for x in tmi_data_copy.columns if x not in cat_cols + target_col + Id_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n\n#Binary columns with 2 values\nbin_cols   = ['is_staff', 'ins_life_health_solict_in']\n#Columns more than 2 values\nmulti_cols = ['gender_ds','age_group', 'contry_region_ds', 'tenure_group','beacon_score_group', 'family_size_group', 'income_group']\n\n#Label encoding Binary columns\nle = LabelEncoder()\nfor i in bin_cols :\n    tmi_data_copy[i] = le.fit_transform(tmi_data_copy[i])\n    \n#Duplicating columns for multi value columns\ntmi_data_copy = pd.get_dummies(data = tmi_data_copy,columns = multi_cols)\n\n#Scaling Numerical columns\nstd = StandardScaler()\nscaled = std.fit_transform(tmi_data_copy[num_cols])\nscaled = pd.DataFrame(scaled,columns=num_cols)\n\n#dropping original values merging scaled values for numerical columns\ndf_tmi_data_copy_og = tmi_data_copy.copy()\ntmi_data_copy = tmi_data_copy.drop(columns = num_cols,axis = 1)\ntmi_data_copy = tmi_data_copy.merge(scaled,left_index=True,right_index=True,how = \"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tmi_data_copy.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Correlation Analysis"},{"metadata":{"trusted":false},"cell_type":"code","source":"#correlation\ncorrelation = tmi_data_copy.corr()\n#tick labels\nmatrix_cols = correlation.columns.tolist()\n#convert to array\ncorr_array  = np.array(correlation)\n\n#Plotting\ntrace = go.Heatmap(z = corr_array,\n                   x = matrix_cols,\n                   y = matrix_cols,\n                   colorscale = \"Viridis\",\n                   colorbar   = dict(title = \"Pearson Correlation coefficient\",\n                                     titleside = \"right\"\n                                    ) ,\n                  )\n\nlayout = go.Layout(dict(title = \"Correlation Matrix for variables\",\n                        autosize = False,\n                        height  = 720,\n                        width   = 800,\n                        margin  = dict(r = 0 ,l = 210,\n                                       t = 25,b = 210,\n                                      ),\n                        yaxis   = dict(tickfont = dict(size = 9)),\n                        xaxis   = dict(tickfont = dict(size = 9))\n                       )\n                  )\n\ndata = [trace]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Threshold for removing correlated variables\nthreshold = 0.7\n\n# Absolute value correlation matrix\ncorr_matrix = tmi_data.corr().abs()\ncorr_matrix.head()\n\n# Upper triangle of correlations\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nupper.head()\n\n# Select columns with correlations above threshold\nto_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n\nprint('There are %d columns to remove.' % (len(to_drop)))\nto_drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"to_drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tmi_data_copy=tmi_data_copy.drop(columns=to_drop)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Model Building"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Import libraries\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import f1_score, roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neural_network import MLPClassifier\nfrom imblearn.pipeline import make_pipeline as make_pipeline_imb\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.metrics import classification_report_imbalanced\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a regular train_test_split, the ratio of target variable 0s:1s approx. = 6.4 : 1 (86.5% vs. 13.5%) "},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#splitting train and test data \ntrain,test = train_test_split(tmi_data_copy,test_size = .30 ,random_state = 123)\n    \n##seperating dependent and independent variables\ncols    = [i for i in tmi_data_copy.columns if i not in Id_col + target_col]\ntrain_X = train[cols]\ntrain_Y = train[target_col]\ntest_X  = test[cols]\ntest_Y  = test[target_col]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to solve the imbalanced dataset problem, I use random under sampling method to undersampling the majorities (0s), and to reduce the datasets from 12 million records down to roughly 3.2 million records. The new 0s:1s ratio is 1:1"},{"metadata":{"trusted":false},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter\n\nid_col = ['cust_id']\ntarget_col = ['target_istravel']\ncols    = [i for i in tmi_data_copy.columns if i not in target_col + id_col]\n\nrus_X = tmi_data_copy[cols]\nrus_Y = tmi_data_copy[target_col]\n\nrus = RandomUnderSampler(random_state=0)\nus_rus_X,us_rus_Y = rus.fit_sample(rus_X,rus_Y.values.ravel())\nprint('Resampled dataset shape %s' % Counter(us_rus_Y))\n\nus_rus_X = pd.DataFrame(data = us_rus_X,columns=cols)\nus_rus_Y = pd.DataFrame(data = us_rus_Y,columns=target_col)\n\n\n\n#Split train and test data\nrus_train_X,rus_test_X,rus_train_Y,rus_test_Y = train_test_split(us_rus_X,us_rus_Y,\n                                                                         test_size = .30 ,\n                                                                         random_state = 123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc\n\ndef model(algorithm,dtrain_x,dtrain_y,dtest_x,dtest_y,of_type):\n    \n    print (\"*****************************************************************************************\")\n    print (\"MODEL - OUTPUT\")\n    print (\"*****************************************************************************************\")\n    algorithm.fit(dtrain_x,dtrain_y)\n    predictions = algorithm.predict(dtest_x)\n    \n    print (algorithm)\n    print (\"\\naccuracy_score :\",accuracy_score(dtest_y,predictions))\n    \n    print (\"\\nclassification report :\\n\",(classification_report(dtest_y,predictions)))\n        \n    plt.figure(figsize=(13,10))\n    plt.subplot(221)\n    sns.heatmap(confusion_matrix(dtest_y,predictions),annot=True,fmt = \"d\",linecolor=\"k\",linewidths=3)\n    plt.title(\"CONFUSION MATRIX\",fontsize=20)\n    \n    predicting_probabilites = algorithm.predict_proba(dtest_x)[:,1]\n    fpr,tpr,thresholds = roc_curve(dtest_y,predicting_probabilites)\n    plt.subplot(222)\n    plt.plot(fpr,tpr,label = (\"Area_under the curve :\",auc(fpr,tpr)),color = \"r\")\n    plt.plot([1,0],[1,0],linestyle = \"dashed\",color =\"k\")\n    plt.legend(loc = \"best\")\n    plt.title(\"ROC - CURVE & AREA UNDER CURVE\",fontsize=20)\n    \n    if  of_type == \"feat\":\n        \n        dataframe = pd.DataFrame(algorithm.feature_importances_,dtrain_x.columns).reset_index()\n        dataframe = dataframe.rename(columns={\"index\":\"features\",0:\"coefficients\"})\n        dataframe = dataframe.sort_values(by=\"coefficients\",ascending = False)\n        plt.figure(figsize=(50,80))\n        plt.subplot(223)\n        ax = sns.barplot(x = \"coefficients\" ,y =\"features\",data=dataframe,palette=\"husl\")\n        plt.title(\"FEATURE IMPORTANCES\",fontsize =22)\n        for i,j in enumerate(dataframe[\"coefficients\"]):\n            ax.text(.011,i,j,weight = \"bold\")\n        print(dataframe)\n    \n    elif of_type == \"coef\" :\n        \n        dataframe = pd.DataFrame(algorithm.coef_.ravel(),dtrain_x.columns).reset_index()\n        dataframe = dataframe.rename(columns={\"index\":\"features\",0:\"coefficients\"})\n        dataframe = dataframe.sort_values(by=\"coefficients\",ascending = False)\n        plt.figure(figsize=(50,80))\n        plt.subplot(223)\n        ax = sns.barplot(x = \"coefficients\" ,y =\"features\",data=dataframe,palette=\"husl\")\n        plt.title(\"FEATURE IMPORTANCES\",fontsize =22)\n        for i,j in enumerate(dataframe[\"coefficients\"]):\n            ax.text(.011,i,j,weight = \"bold\")\n        print(dataframe)\n            \n    elif of_type == \"none\" :\n        return (algorithm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.1 Random Forest"},{"metadata":{"trusted":false},"cell_type":"code","source":"#random forest rus_removed highly correlated variables + num_days_since_last_X, avg_num_days\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf =RandomForestClassifier()\nmodel(rf,train_X,train_Y.values.ravel(),test_X,test_Y.values.ravel(),\"feat\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#random forest rus_removed highly correlated variables + num_days_since_last_X, avg_num_days\n#tuning parameters - need to adjust weight for classes , adjust randomness, max feature = 50\nrf =RandomForestClassifier()\nmodel(rf,rus_train_X,rus_train_Y.values.ravel(),test_X,test_Y.values.ravel(),\"feat\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This random forest model will be selected as our baseline model for the following reasons:\n-- AUR = 0.8, Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. in another word, higher the auc, better the model is at distinguishing between customers those who will book travel vs those who won't.\n-- recall/true positive rate = 0.79, among those who are actually booking travel in next 3 months with TD, 79% of the times the model is predicting it as positive. \n\nHowever, further improvements: \n-- instead of using undersampled datasets for training(this may cause information loss), use regular full datasets by adjusting weights for classes. Give a higher weight for 1s, and lower weights for 0s. \n-- hyperparameters tuning: \nadjust n_estimators, to increase the number of trees. \nadjust randomness. right now, it's by default, try to adjust the randomness to a higher number. \nadjust max_feature, try to select more variables for each trees, to have a better understanding of feature importance. \n-- cross validation "},{"metadata":{"trusted":false},"cell_type":"code","source":"#random forest rus_with all variables\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf =RandomForestClassifier()\nmodel(rf,rus_train_X,rus_train_Y.values.ravel(),test_X,test_Y.values.ravel(),\"feat\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"feature_list = list(rus_train_X.columns)\n# Get numerical feature importances\nimportances = list(rf.feature_importances_)\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_values = list(range(len(importances)))\n# List of features sorted from most to least important\nsorted_importances = [importance[1] for importance in feature_importances]\nsorted_features = [importance[0] for importance in feature_importances]\n# Cumulative importances\ncumulative_importances = np.cumsum(sorted_importances)\n# Make a line graph\nplt.plot(x_values, cumulative_importances, 'g-')\n# Draw line at 95% of importance retained\nplt.hlines(y = 0.95, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dashed')\n# Format x ticks and labels\nplt.xticks(x_values, sorted_features, rotation = 'vertical')\n# Axis labels and title\nplt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Find number of features for cumulative importance of 95%\n# Add 1 because Python is zero-indexed\nprint('Number of features for 70% importance:', np.where(cumulative_importances > 0.7)[0][0] + 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Extract the names of the most important features\nimportant_feature_names = [feature[0] for feature in feature_importances[0:45]]\n# Find the columns of the most important features\nimportant_indices = [feature_list.index(feature) for feature in important_feature_names]\n# Create training and testing sets with only the important features\n\n#important_train_features = rus_train_X[:,important_indices]\n#important_test_features = test_X[:,important_indices]\n\n#important_train_features\n\n# Sanity check on operations\n#print('Important train features shape:', important_train_features.shape)\n#print('Important test features shape:', important_test_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import cross_validation\nfrom sklearn.grid_search import GridSearchCV\nfrom time import time\nimport matplotlib.pyplot as plt\nfrom operator import itemgetter","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"param_grid = [\n{\"n_estimators\": [10, 20, 25],\n \"max_depth\": [3, 6, None],\n #'min_samples_split' : [2, 5, 10],\n#'min_samples_leaf' : [1, 3, 5] ,\n }\n]\n\ngrid_search_forest = GridSearchCV(rf, param_grid, cv=3)\ngrid_search_forest.fit(rus_train_X, rus_train_Y.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_forest.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.2 XGBOOST"},{"metadata":{},"cell_type":"markdown","source":"XGBOOST is considered for baseline model as it works well with imbalanced data, and can handle missing values. (two major problems with our datasets) "},{"metadata":{"trusted":false},"cell_type":"code","source":"def xgb_classifier(X_train, X_test, y_train, y_test, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n    \n    alg = XGBClassifier(learning_rate=0.1, n_estimators=140, max_depth=5,\n                        min_child_weight=3, gamma=0.2, subsample=0.6, colsample_bytree=1.0,\n                        objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n\n    if useTrainCV:\n        print(\"Start Feeding Data\")\n        xgb_param = alg.get_xgb_params()\n        xgtrain = xgb.DMatrix(X_train.values, label=y_train.values)\n        # xgtest = xgb.DMatrix(X_test.values, label=y_test.values)\n        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n                          early_stopping_rounds=early_stopping_rounds)\n        alg.set_params(n_estimators=cvresult.shape[0])\n\n   \n    print('Start Training')\n    alg.fit(X_train, y_train, eval_metric='auc')\n\n    # param_test1 = {}\n    # gsearch1 = GridSearchCV(estimator=XGBClassifier(learning_rate=0.1, n_estimators=140, max_depth=5,\n    #                                                 min_child_weight=3, gamma=0.2, subsample=0.8,\n    #                                                 colsample_bytree=1.0,\n    #                                                 objective='binary:logistic', nthread=4, scale_pos_weight=1,\n    #                                                 seed=27),\n    #                         param_grid=param_test1,\n    #                         scoring='f1',\n    #                         n_jobs=4, iid=False, cv=5)\n    # gsearch1.fit(X_train, y_train)\n    # print(gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_)\n\n  \n    print(\"Start Predicting\")\n    predictions = alg.predict(X_test)\n    pred_proba = alg.predict_proba(X_test)[:, 1]\n\n\n \n    print(\"Accuracy - Train : %.4g\" % metrics.accuracy_score(y_test, predictions))\n    print(\"AUC - Train: %f\" % metrics.roc_auc_score(y_test, pred_proba))\n    print(\"F1 Score - Train): %f\" % metrics.f1_score(y_test, predictions))\n\n    feat_imp = alg.feature_importances_\n    feat = X_train.columns.tolist()\n    # clf.best_estimator_.booster().get_fscore()\n    res_df = pd.DataFrame({'Features': feat, 'Importance': feat_imp}).sort_values(by='Importance', ascending=False)\n    res_df.plot('Features', 'Importance', kind='bar', title='Feature Importances')\n    plt.ylabel('Feature Importance Score')\n    plt.show()\n    print(res_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#xgb removed highly correlated variables + num_days_since_last_X, avg_num_days  \nxgb_classifier(train_X, test_X, train_Y, test_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#xgb with all variables\nxgb_classifier(rus_train_X, test_X, rus_train_Y, test_Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hyperparameter tuning"},{"metadata":{},"cell_type":"markdown","source":"# 6.3 XGBOOST V2"},{"metadata":{},"cell_type":"markdown","source":"https://github.com/ParrotPrediction/docker-course-xgboost/tree/master/notebooks/3.%20Going%20deeper"},{"metadata":{},"cell_type":"markdown","source":"# 6.3.1 Spotting the important features "},{"metadata":{"trusted":false},"cell_type":"code","source":"#Specify training parameters - we are going to use 5 stump decision trees with average learning rate.\n# specify training parameters\nparams = {\n    'objective':'binary:logistic',\n    'max_depth':1,\n    'silent':1,\n    'eta':0.5\n}\n\nnum_rounds = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Train the model. In the same time specify watchlist to observe it's performance on the test set.\n# see how does it perform\nwatchlist  = [(dtest,'test'), (dtrain,'train')] # native interface only\nbst = xgb.train(params, train_X, num_rounds, watchlist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hopefully there are better ways to figure out which features really matter. We can use built-in function plot_importance that will create a plot presenting most important features due to some criterias. We will analyze the impact of each feature for all splits and all trees and visualize results."},{"metadata":{"trusted":false},"cell_type":"code","source":"#See which feature provided the most gain:\nxgb.plot_importance(bst, importance_type='gain', xlabel='Gain')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"xgb.plot_importance(bst)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"F-score - sums up how many times a split was performed on each feature."},{"metadata":{"trusted":false},"cell_type":"code","source":"importances = bst.get_fscore()\nimportances","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# create df\nimportance_df = pd.DataFrame({\n        'Splits': list(importances.values()),\n        'Feature': list(importances.keys())\n    })\nimportance_df.sort_values(by='Splits', inplace=True)\nimportance_df.plot(kind='barh', x='Feature', figsize=(8,6), color='orange')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.3.2 Bias/Variance trade-off"},{"metadata":{},"cell_type":"markdown","source":"There are two general types of errors made by classifiers - bias and variance errors.\nBias error is the overall difference between expected predictions made by the model and true values.\nVariance error describes how much predictions for the given point vary.\nThe desired state is when both errors are as low as possible.\n"},{"metadata":{},"cell_type":"markdown","source":"Knowing the errors introduced with bias and variance we can proceed to how these relate to training the model. We will use the plot taken from scikit-learn docs to help us visualize the underfitting and overfitting issues.\nFor underfitting we say that model suffers from high bias (too simple) (low variance)\nFor overfitting we say that model suffers from high variance (over-complicated, unstable) (low bias)\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"%matplotlib inline\n\nfrom sklearn.learning_curve import validation_curve\nfrom sklearn.datasets import load_svmlight_files\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.datasets import make_classification\nfrom xgboost.sklearn import XGBClassifier\nfrom scipy.sparse import vstack\n\n# reproducibility\nseed = 123\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#We will divide into 5 stratified folds (the same distibution of labels in each fold) for testing\n\ncv = StratifiedKFold(y, n_folds=5, shuffle=True, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"default_params = {\n    'objective': 'binary:logistic',\n    'max_depth': 1,\n    'learning_rate': 0.3,\n    'silent': 1.0\n}\n\nn_estimators_range = np.linspace(1, 200, 10).astype('int')\n\ntrain_scores, test_scores = validation_curve(\n    XGBClassifier(**default_params),\n    X, y,\n    param_name = 'n_estimators',\n    param_range = n_estimators_range,\n    cv=cv,\n    scoring='accuracy'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Show the validation curve plot\n\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\nfig = plt.figure(figsize=(10, 6), dpi=100)\n\nplt.title(\"Validation Curve with XGBoost (eta = 0.3)\")\nplt.xlabel(\"number of trees\")\nplt.ylabel(\"Accuracy\")\nplt.ylim(0.7, 1.1)\n\nplt.plot(n_estimators_range,\n             train_scores_mean,\n             label=\"Training score\",\n             color=\"r\")\n\nplt.plot(n_estimators_range,\n             test_scores_mean, \n             label=\"Cross-validation score\",\n             color=\"g\")\n\nplt.fill_between(n_estimators_range, \n                 train_scores_mean - train_scores_std,\n                 train_scores_mean + train_scores_std, \n                 alpha=0.2, color=\"r\")\n\nplt.fill_between(n_estimators_range,\n                 test_scores_mean - test_scores_std,\n                 test_scores_mean + test_scores_std,\n                 alpha=0.2, color=\"g\")\n\nplt.axhline(y=1, color='k', ls='dashed')\n\nplt.legend(loc=\"best\")\nplt.show()\n\ni = np.argmax(test_scores_mean)\nprint(\"Best cross-validation result ({0:.2f}) obtained for {1} trees\".format(test_scores_mean[i], n_estimators_range[i]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dealing with high variance: In XGBoost you can try to:\n\nreduce depth of each tree (max_depth),\nincrease min_child_weight parameter,\nincrease gamma parameter,\nadd more randomness using subsample, colsample_bytree parameters,\nincrease lambda and alpha regularization parameters"},{"metadata":{},"cell_type":"markdown","source":"Dealing with high bias\nIn XGBoost you can do it by:\n\nincrease depth of each tree (max_depth),\ndecrease min_child_weight parameter,\ndecrease gamma parameter,\ndecrease lambda and alpha regularization parameters "},{"metadata":{"trusted":false},"cell_type":"code","source":"default_params = {\n    'objective': 'binary:logistic',\n    'max_depth': 2, # changed\n    'learning_rate': 0.3,\n    'silent': 1.0,\n    'colsample_bytree': 0.6, # added\n    'subsample': 0.7 # added\n}\n\nn_estimators_range = np.linspace(1, 200, 10).astype('int')\n\ntrain_scores, test_scores = validation_curve(\n    XGBClassifier(**default_params),\n    X, y,\n    param_name = 'n_estimators',\n    param_range = n_estimators_range,\n    cv=cv,\n    scoring='accuracy'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\nfig = plt.figure(figsize=(10, 6), dpi=100)\n\nplt.title(\"Validation Curve with XGBoost (eta = 0.3)\")\nplt.xlabel(\"number of trees\")\nplt.ylabel(\"Accuracy\")\nplt.ylim(0.7, 1.1)\n\nplt.plot(n_estimators_range,\n             train_scores_mean,\n             label=\"Training score\",\n             color=\"r\")\n\nplt.plot(n_estimators_range,\n             test_scores_mean, \n             label=\"Cross-validation score\",\n             color=\"g\")\n\nplt.fill_between(n_estimators_range, \n                 train_scores_mean - train_scores_std,\n                 train_scores_mean + train_scores_std, \n                 alpha=0.2, color=\"r\")\n\nplt.fill_between(n_estimators_range,\n                 test_scores_mean - test_scores_std,\n                 test_scores_mean + test_scores_std,\n                 alpha=0.2, color=\"g\")\n\nplt.axhline(y=1, color='k', ls='dashed')\n\nplt.legend(loc=\"best\")\nplt.show()\n\ni = np.argmax(test_scores_mean)\nprint(\"Best cross-validation result ({0:.2f}) obtained for {1} trees\".format(test_scores_mean[i], n_estimators_range[i]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.3.3 Hyperparameter Tuning"},{"metadata":{"trusted":false},"cell_type":"code","source":"from xgboost.sklearn import XGBClassifier\n\nfrom sklearn.grid_search import GridSearchCV, RandomizedSearchCV\nfrom sklearn.datasets import make_classification\nfrom sklearn.cross_validation import StratifiedKFold\n\nfrom scipy.stats import randint, uniform\n\n# reproducibility\nseed = 123\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cv = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Randomized Grid-Search\nWhen the number of parameters and their values is getting big traditional grid-search approach quickly becomes ineffective. A possible solution might be to randomly pick certain parameters from their distribution. While it's not an exhaustive solution, it's worth giving a shot."},{"metadata":{"trusted":false},"cell_type":"code","source":"\nparams_dist_grid = {\n    'max_depth': [1, 2, 3, 4],\n    'gamma': [0, 0.5, 1],\n    'n_estimators': randint(1, 1001), # uniform discrete random distribution\n    'learning_rate': uniform(), # gaussian distribution\n    'subsample': uniform(), # gaussian distribution\n    'colsample_bytree': uniform() # gaussian distribution\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rs_grid = RandomizedSearchCV(\n    estimator=XGBClassifier(**params_fixed, seed=seed),\n    param_distributions=params_dist_grid,\n    n_iter=10,\n    cv=cv,\n    scoring='auc',\n    random_state=seed\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rs_grid.fit(train_X, train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rs_grid.grid_scores_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rs_grid.best_estimator_\nrs_grid.best_params_\nrs_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.3.4 Adjust weights for imbalanced data"},{"metadata":{"trusted":false},"cell_type":"code","source":"params['scale_pos_weight'] = 1/6.4","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"bst = xgb.train(params, dtrain, num_rounds)\ny_test_preds = (bst.predict(dtest) > 0.5).astype('int')\n\npd.crosstab(\n    pd.Series(y_test, name='Actual'),\n    pd.Series(y_test_preds, name='Predicted'),\n    margins=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Other Methodologies Attempted "},{"metadata":{},"cell_type":"markdown","source":"# 6.1 Logistic Regression"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Logistic regression removed highly correlated variables + num_days_since_last_X, avg_num_days \n#using regular train_test datasets \nfrom sklearn.linear_model import LogisticRegression\nlog = LogisticRegression()\nmodel(log,train_X,train_Y.values.ravel(),test_X,test_Y.values.ravel(),\"coef\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"recall of 1.0 indicates that the model starts to cheat itself, the model is unusable."},{"metadata":{"trusted":false},"cell_type":"code","source":"#Logistic regression removed highly correlated variables + num_days_since_last_X, avg_num_days \n#using undersampled datasets (0s:1s = 1:1) for training, and regular datasets (0s:1s = 6.4:1) for testing.\nlog = LogisticRegression()\nmodel(log,rus_train_X,rus_train_Y.values.ravel(),test_X,test_Y.values.ravel(),\"coef\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.1 Logistic Regression v2"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score,recall_score\n#from yellowbrick.classifier import DiscriminationThreshold\n#splitting train and test data \ntrain,test = train_test_split(tmi_data_copy,test_size = .30 ,random_state = 111)\n    \n##seperating dependent and independent variables\ncols    = [i for i in tmi_data_copy.columns if i not in Id_col + target_col]\ntrain_X = train[cols]\ntrain_Y = train[target_col]\ntest_X  = test[cols]\ntest_Y  = test[target_col]\n\n#Function attributes\n#dataframe     - processed dataframe\n#Algorithm     - Algorithm used \n#training_x    - predictor variables dataframe(training)\n#testing_x     - predictor variables dataframe(testing)\n#training_y    - target variable(training)\n#training_y    - target variable(testing)\n#cf - [\"coefficients\",\"features\"](cooefficients for logistic \n                                 #regression,features for tree based models)\n\n#threshold_plot - if True returns threshold plot for model\n    \ndef travel_booking_prediction(algorithm,training_x,testing_x,\n                             training_y,testing_y,cols,cf) :\n    \n    #model\n    algorithm.fit(training_x,training_y.values.ravel())\n    predictions   = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    #coeffs\n    if   cf == \"coefficients\" :\n        coefficients  = pd.DataFrame(algorithm.coef_.ravel())\n    elif cf == \"features\" :\n        coefficients  = pd.DataFrame(algorithm.feature_importances_)\n        \n    column_df     = pd.DataFrame(cols)\n    coef_sumry    = (pd.merge(coefficients,column_df,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    \n    print (algorithm)\n    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n    print (\"Accuracy   Score : \",accuracy_score(testing_y,predictions))\n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y,predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n    \n    #plot confusion matrix\n    trace1 = go.Heatmap(z = conf_matrix ,\n                        x = [\"No Travel Booking\",\"Travel Booking\"],\n                        y = [\"No Travel Booking\",\"Travel Booking\"],\n                        showscale  = False,colorscale = \"Picnic\",\n                        name = \"matrix\")\n    \n    #plot roc curve\n    trace2 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n    trace3 = go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot'))\n    \n    #plot coeffs\n    trace4 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\",\n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Picnic\",\n                                  line = dict(width = .6,color = \"black\")))\n    \n    #subplots\n    fig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                            subplot_titles=('Confusion Matrix',\n                                            'Receiver operating characteristic',\n                                            'Feature Importances'))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,1,2)\n    fig.append_trace(trace4,2,1)\n    \n    fig['layout'].update(showlegend=False, title=\"Model performance\" ,\n                         autosize = False,height = 900,width = 800,\n                         plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                         paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                         margin = dict(b = 195))\n    fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n    fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n    fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True,tickfont = dict(size = 10),\n                                        tickangle = 90))\n    py.iplot(fig)\n    \n    #if threshold_plot == True : \n        #visualizer = DiscriminationThreshold(algorithm)\n        #visualizer.fit(training_x,training_y)\n        #visualizer.poof()\n        \nlogit  = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\ntravel_booking_prediction(logit,train_X,test_X,train_Y,test_Y,\n                         cols,\"coefficients\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.2 Logistic Regression with Random Undersampling the Majority Class"},{"metadata":{},"cell_type":"markdown","source":"- Randomly pick a point from the majority class."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter\n\nid_col = ['cust_id']\ntarget_col = ['target_istravel']\ncols    = [i for i in tmi_data_copy.columns if i not in target_col + id_col]\n\nrus_X = tmi_data_copy[cols]\nrus_Y = tmi_data_copy[target_col]\n\nrus = RandomUnderSampler(random_state=0)\nus_rus_X,us_rus_Y = rus.fit_sample(rus_X,rus_Y.values.ravel())\nprint('Resampled dataset shape %s' % Counter(us_rus_Y))\n\nus_rus_X = pd.DataFrame(data = us_rus_X,columns=cols)\nus_rus_Y = pd.DataFrame(data = us_rus_Y,columns=target_col)\n\n\n\n#Split train and test data\nrus_train_X,rus_test_X,rus_train_Y,rus_test_Y = train_test_split(us_rus_X,us_rus_Y,\n                                                                         test_size = .30 ,\n                                                                         random_state = 123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"logit_rus = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\ntravel_booking_prediction(logit_rus,rus_train_X,test_X,rus_train_Y,test_Y,\n                         cols,\"coefficients\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.3 Recursive Feature Elimination"},{"metadata":{},"cell_type":"markdown","source":"Recursive Feature Elimination (RFE) is based on the idea to repeatedly construct a model and choose either the best or worst performing feature, setting the feature aside and then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. The goal of RFE is to select features by recursively considering smaller and smaller sets of features."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.feature_selection import RFE\n\nlogit = LogisticRegression()\n\nrfe = RFE(logit,10)\nrfe = rfe.fit(us_rus_X,us_rus_Y.values.ravel())\n\nrfe.support_\nrfe.ranking_\n\n#identified columns Recursive Feature Elimination\nidc_rfe = pd.DataFrame({\"rfe_support\" :rfe.support_,\n                       \"columns\" : [i for i in tmi_data_copy.columns if i not in Id_col + target_col],\n                       \"ranking\" : rfe.ranking_,\n                      })\ncols = idc_rfe[idc_rfe[\"rfe_support\"] == True][\"columns\"].tolist()\n\n\n#separating train and test data\ntrain_rf_X = us_rus_X[cols]\ntrain_rf_Y = us_rus_Y\ntest_rf_X  = test[cols]\ntest_rf_Y  = test[target_col]\n\nlogit_rfe = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n#applying model\ntravel_booking_prediction(logit_rfe,train_rf_X,test_rf_X,train_rf_Y,test_rf_Y,\n                         cols,\"coefficients\")\n\ntab_rk = ff.create_table(idc_rfe)\npy.iplot(tab_rk)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.4 Univariate Selection"},{"metadata":{},"cell_type":"markdown","source":"- Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n- uses the chi squared (chi^2) statistical test for non-negative features to select the best features"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest\n\n#select columns\ncols = [i for i in tmi_data_copy.columns if i not in Id_col + target_col ]\n\n#dataframe with non negative values\ndf_x = df_tmi_data_copy_og[cols]\ndf_y = df_tmi_data_copy_og[target_col]\n\n#fit model with k= 3\nselect = SelectKBest(score_func = chi2,k = 3)\nfit    = select.fit(df_x,df_y)\n\n#Summerize scores\nprint (\"scores\")\nprint (fit.scores_)\nprint (\"P - Values\")\nprint (fit.pvalues_)\n\n#create dataframe\nscore = pd.DataFrame({\"features\":cols,\"scores\":fit.scores_,\"p_values\":fit.pvalues_ })\nscore = score.sort_values(by = \"scores\" ,ascending =False)\n\n\n#createing new label for categorical and numerical columns\nscore[\"feature_type\"] = np.where(score[\"features\"].isin(num_cols),\"Numerical\",\"Categorical\")\n\n#plot\ntrace  = go.Scatter(x = score[score[\"feature_type\"] == \"Categorical\"][\"features\"],\n                    y = score[score[\"feature_type\"] == \"Categorical\"][\"scores\"],\n                    name = \"Categorial\",mode = \"lines+markers\",\n                    marker = dict(color = \"red\",\n                                  line = dict(width =1))\n                   )\n\ntrace1 = go.Bar(x = score[score[\"feature_type\"] == \"Numerical\"][\"features\"],\n                y = score[score[\"feature_type\"] == \"Numerical\"][\"scores\"],name = \"Numerical\",\n                marker = dict(color = \"royalblue\",\n                              line = dict(width =1)),\n                xaxis = \"x2\",yaxis = \"y2\"\n               )\nlayout = go.Layout(dict(title = \"Scores for Categorical & Numerical features\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     tickfont = dict(size =10),\n                                     domain=[0, 0.7],\n                                     tickangle = 90,zerolinewidth=1,\n                                     ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"scores\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        margin = dict(b=200),\n                        xaxis2=dict(domain=[0.8, 1],tickangle = 90,\n                                    gridcolor = 'rgb(255, 255, 255)'),\n                        yaxis2=dict(anchor='x2',gridcolor = 'rgb(255, 255, 255)')\n                        )\n                  )\n\ndata=[trace,trace1]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.5 Decision Tree Based"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn import tree\nfrom graphviz import Source\nfrom IPython.display import SVG,display","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#top 5 categorical features\nfeatures_cat  = score[score[\"feature_type\"] == \"Categorical\"][\"features\"][:5].tolist()\n\n#top 5 numerical features\nfeatures_num  = score[score[\"feature_type\"] == \"Numerical\"][\"features\"][:5].tolist()\n\n\n#Function attributes\n#columns        - selected columns\n#maximum_depth  - depth of tree\n#criterion_type - [\"gini\" or \"entropy\"]\n#split_type     - [\"best\" or \"random\"]\n#Model Performance - True (gives model output)\n\ndef plot_decision_tree(columns,maximum_depth,criterion_type,\n                       split_type,model_performance = None) :\n    \n    #separating dependent and in dependent variables\n    dtc_x = df_x[columns]\n    dtc_y = df_y[target_col]\n    \n    #model\n    dt_classifier = DecisionTreeClassifier(max_depth = maximum_depth,\n                                           splitter  = split_type,\n                                           criterion = criterion_type,\n                                          )\n    dt_classifier.fit(dtc_x,dtc_y)\n    \n    #plot decision tree\n    graph = Source(tree.export_graphviz(dt_classifier,out_file=None,\n                                        rounded=True,proportion = False,\n                                        feature_names = columns, \n                                        precision  = 2,\n                                        class_names=[\"No Travel Booking\",\"Travel Booking\"],\n                                        filled = True                         \n                                       )\n                  )\n    \n    #model performance\n    if model_performance == True :\n        travel_booking_prediction(dt_classifier,\n                                 dtc_x,test_X[columns],\n                                 dtc_y,test_Y,\n                                 columns,\"features\")\n    display(graph)\n    \nplot_decision_tree(features_num,5,\"gini\",\"best\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_decision_tree(features_cat,5,\"entropy\",\"best\",\n                   model_performance = True ,)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Need to edit following code"},{"metadata":{"trusted":false},"cell_type":"code","source":"#using contract,tenure and paperless billing variables\ncolumns = ['tenure','Contract_Month-to-month', 'PaperlessBilling',\n           'Contract_One year', 'Contract_Two year']\n\nplot_decision_tree(columns,5,\"gini\",\"best\",model_performance= True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.6 KNN Classifier"},{"metadata":{},"cell_type":"markdown","source":"Applying knn algorithm to random undersampled data."},{"metadata":{"trusted":false},"cell_type":"code","source":"def travel_booking_prediction_alg(algorithm,training_x,testing_x,\n                                 training_y,testing_y) :\n    \n    #model\n    algorithm.fit(training_x,training_y)\n    predictions   = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    \n    print (algorithm)\n    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n    print (\"Accuracy Score   : \",accuracy_score(testing_y,predictions))\n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y,predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc)\n    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n     \n    #plot roc curve\n    trace1 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2),\n                       )\n    trace2 = go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot'))\n    \n    #plot confusion matrix\n    trace3 = go.Heatmap(z = conf_matrix ,x = [\"No Travel Booking\",\"Travel Booking\"],\n                        y = [\"No Travel Booking\",\"Travel Booking\",\n                        showscale  = False,colorscale = \"Blues\",name = \"matrix\",\n                        xaxis = \"x2\",yaxis = \"y2\"\n                       )\n    \n    layout = go.Layout(dict(title=\"Model performance\" ,\n                            autosize = False,height = 500,width = 800,\n                            showlegend = False,\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(title = \"false positive rate\",\n                                         gridcolor = 'rgb(255, 255, 255)',\n                                         domain=[0, 0.6],\n                                         ticklen=5,gridwidth=2),\n                            yaxis = dict(title = \"true positive rate\",\n                                         gridcolor = 'rgb(255, 255, 255)',\n                                         zerolinewidth=1,\n                                         ticklen=5,gridwidth=2),\n                            margin = dict(b=200),\n                            xaxis2=dict(domain=[0.7, 1],tickangle = 90,\n                                        gridcolor = 'rgb(255, 255, 255)'),\n                            yaxis2=dict(anchor='x2',gridcolor = 'rgb(255, 255, 255)')\n                           )\n                  )\n    data = [trace1,trace2,trace3]\n    fig = go.Figure(data=data,layout=layout)\n    \n    py.iplot(fig)\n    \n                             \n    ##if threshold_plot == True : \n        ##visualizer = DiscriminationThreshold(algorithm)\n        ##visualizer.fit(training_x,training_y)\n        ##visualizer.poof()\n\n    \nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n           weights='uniform')\ntravel_booking_prediction_alg(knn,rus_train_X,test_X,\n                             rus_train_Y,test_Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.7 Visualizing a decision tree from random forest classifier"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n#function attributes\n#columns  - column used\n#nf_estimators   - The number of trees in the forest.\n#estimated_tree  - tree number to be displayed\n#maximum_depth   - depth of the tree\n#criterion_type  - split criterion type [\"gini\" or \"entropy\"]\n#Model performance - prints performance of model\n\ndef plot_tree_randomforest(columns,nf_estimators,\n                           estimated_tree,maximum_depth,\n                           criterion_type,model_performance = None) :\n    \n    dataframe = df_tmi_data_copy_og[columns + target_col].copy()\n    \n    #train and test datasets\n    rf_x     = dataframe[[i for i in columns if i not in target_col]]\n    rf_y     = dataframe[target_col]\n    \n    #random forest classifier\n    rfc   = RandomForestClassifier(n_estimators = nf_estimators,\n                                   max_depth = maximum_depth,\n                                   criterion = criterion_type,\n                                  )\n    rfc.fit(rf_x,rf_y.values.ravel())\n    \n    estimated_tree = rfc.estimators_[estimated_tree]\n    \n    graph = Source(tree.export_graphviz(estimated_tree,out_file=None,\n                                        rounded=True,proportion = False,\n                            feature_names = columns, \n                            precision  = 2,\n                            class_names=[\"No Travel Booking\",\"Travel Booking\"],\n                            filled = True))\n    display(graph)\n    \n    #model performance\n    if model_performance == True :\n        travel_booking_prediction(rfc,\n                                 rf_x,test_X[columns],\n                                 rf_y,test_Y,\n                                 columns,\"features\")\n        \n\ncols1 = [ i for i in train_X.columns if i not in target_col + Id_col] \nplot_tree_randomforest(cols1,100,99,3,\"entropy\",True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.8 Random Forest Classifier"},{"metadata":{"trusted":false},"cell_type":"code","source":"#making 10 trees with random forest.\nn = np.arange(0,10).tolist()\ncols1 = [ i for i in train_X.columns if i not in target_col + Id_col] \nfor i in n :\n    plot_tree_randomforest(cols1,10,i,3,\"entropy\",model_performance=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#making 10 trees with random forest for columns \n#selected from recursive feature elimination\n\nn = np.arange(0,10).tolist()\ncols = idc_rfe[idc_rfe[\"rfe_support\"] == True][\"columns\"].tolist() \nfor i in n :\n    plot_tree_randomforest(cols,10,i,3,\"gini\",model_performance=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.9 Gaussian Naive Bayes"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB(priors=None)\n\ntravel_booking_prediction_alg(gnb,rus_train_X,test_X,rus_train_Y,test_Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.10 Support Vector Machine "},{"metadata":{},"cell_type":"markdown","source":"“Support Vector Machine” (SVM) is a supervised machine learning algorithm which can be used for both classification or regression challenges. it is mostly used in classification problems. In this algorithm, we plot each data item as a point in n-dimensional space .where n is number of features you have) with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyper-plane that differentiate the two classes"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.svm import SVC\n\n#Support vector classifier\n#using linear hyper plane\nsvc_lin  = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n               decision_function_shape='ovr', degree=3, gamma=1.0, kernel='linear',\n               max_iter=-1, probability=True, random_state=None, shrinking=True,\n               tol=0.001, verbose=False)\n\ncols = [i for i in tmi_data_copy.columns if i not in Id_col + target_col]\ntravel_booking_prediction(svc_lin,rus_train_X,test_X,rus_train_Y,test_Y,\n                         cols,\"coefficients\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.11 Tuning Parameters for Support Vector Machine"},{"metadata":{"trusted":false},"cell_type":"code","source":"#tuning parameters\n#Support vector classifier\n#using non-linear hyper plane(\"rbf\")\n\nsvc_rbf  = SVC(C=1.0, kernel='rbf', \n               degree= 3, gamma=1.0, \n               coef0=0.0, shrinking=True,\n               probability=True,tol=0.001,\n               cache_size=200, class_weight=None,\n               verbose=False,max_iter= -1,\n               random_state=None)\n\ntravel_booking_prediction_alg(svc_rbf,rus_train_X,test_X,rus_train_Y,test_Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.12 LightGBMClassifier"},{"metadata":{"trusted":false},"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nlgbm_c = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n                        learning_rate=0.5, max_depth=7, min_child_samples=20,\n                        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n                        n_jobs=-1, num_leaves=500, objective='binary', random_state=None,\n                        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n                        subsample_for_bin=200000, subsample_freq=0)\n\ncols = [i for i in tmi_data_copy.columns if i not in Id_col + target_col]\ntravel_booking_prediction(lgbm_c,rus_train_X,test_X,rus_train_Y,test_Y,\n                         cols,\"features\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.13 XGBoost Classifier"},{"metadata":{"trusted":false},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                    colsample_bytree=1, gamma=0, learning_rate=0.9, max_delta_step=0,\n                    max_depth = 7, min_child_weight=1, missing=None, n_estimators=100,\n                    n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n                    silent=True, subsample=1)\n\n\ntravel_booking_prediction(xgc,rus_train_X,test_X,rus_train_Y,test_Y,\n                         cols,\"features\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7 Model Performance"},{"metadata":{},"cell_type":"markdown","source":"# 7.1 Model Performance Metrics"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import cohen_kappa_score\n\n#gives model report in dataframe\ndef model_report(model,training_x,testing_x,training_y,testing_y,name) :\n    model.fit(training_x,training_y)\n    predictions  = model.predict(testing_x)\n    accuracy     = accuracy_score(testing_y,predictions)\n    recallscore  = recall_score(testing_y,predictions)\n    precision    = precision_score(testing_y,predictions)\n    roc_auc      = roc_auc_score(testing_y,predictions)\n    f1score      = f1_score(testing_y,predictions) \n    kappa_metric = cohen_kappa_score(testing_y,predictions)\n    \n    df = pd.DataFrame({\"Model\"           : [name],\n                       \"Accuracy_score\"  : [accuracy],\n                       \"Recall_score\"    : [recallscore],\n                       \"Precision\"       : [precision],\n                       \"f1_score\"        : [f1score],\n                       \"Area_under_curve\": [roc_auc],\n                       \"Kappa_metric\"    : [kappa_metric],\n                      })\n    return df\n\n#outputs for every model\nmodel1 = model_report(logit,train_X,test_X,train_Y,test_Y,\n                      \"Logistic Regression(Baseline_model)\")\nmodel2 = model_report(logit_rus,rus_train_X,test_X,rus_train_Y,test_Y,\n                      \"Logistic Regression(Random Undersampling)\")\nmodel3 = model_report(logit_rfe,train_rf_X,test_rf_X,train_rf_Y,test_rf_Y,\n                      \"Logistic Regression(RFE)\")\ndecision_tree = DecisionTreeClassifier(max_depth = 9,\n                                       random_state = 123,\n                                       splitter  = \"best\",\n                                       criterion = \"gini\",\n                                      )\nmodel4 = model_report(decision_tree,train_X,test_X,train_Y,test_Y,\n                      \"Decision Tree\")\nmodel5 = model_report(knn,rus_train_X,test_X,rus_train_Y,test_Y,\n                      \"KNN Classifier\")\nrfc = RandomForestClassifier(n_estimators = 1000,\n                             random_state = 123,\n                             max_depth = 9,\n                             criterion = \"gini\")\nmodel6 = model_report(rfc,train_X,test_X,train_Y,test_Y,\n                      \"Random Forest Classifier\")\nmodel7 = model_report(gnb,rus_train_X,test_X,rus_train_Y,test_Y,\n                      \"Naive Bayes\")\nmodel8 = model_report(svc_lin,rus_train_X,test_X,rus_train_Y,test_Y,\n                      \"SVM Classifier Linear\")\nmodel9 = model_report(svc_rbf,rus_train_X,test_X,rus_train_Y,test_Y,\n                      \"SVM Classifier RBF\")\nmodel10 = model_report(lgbm_c,rus_train_X,test_X,rus_train_Y,test_Y,\n                      \"LGBM Classifier\")\nmodel11 = model_report(xgc,rus_train_X,test_X,rus_train_Y,test_Y,\n                      \"XGBoost Classifier\")\n\n#concat all models\nmodel_performances = pd.concat([model1,model2,model3,\n                                model4,model5,model6,\n                                model7,model8,model9,\n                                model10,model11],axis = 0).reset_index()\n\nmodel_performances = model_performances.drop(columns = \"index\",axis =1)\n\ntable  = ff.create_table(np.round(model_performances,4))\n\npy.iplot(table)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7.2 Compare Model Metrics"},{"metadata":{"trusted":false},"cell_type":"code","source":"model_performances\ndef output_tracer(metric,color) :\n    tracer = go.Bar(y = model_performances[\"Model\"] ,\n                    x = model_performances[metric],\n                    orientation = \"h\",name = metric ,\n                    marker = dict(line = dict(width =.7),\n                                  color = color)\n                   )\n    return tracer\n\nlayout = go.Layout(dict(title = \"Model performances\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"metric\",\n                                     zerolinewidth=1,\n                                     ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        margin = dict(l = 250),\n                        height = 780\n                       )\n                  )\n\n\ntrace1  = output_tracer(\"Accuracy_score\",\"#6699FF\")\ntrace2  = output_tracer('Recall_score',\"red\")\ntrace3  = output_tracer('Precision',\"#33CC99\")\ntrace4  = output_tracer('f1_score',\"lightgrey\")\ntrace5  = output_tracer('Kappa_metric',\"#FFCC99\")\n\ndata = [trace1,trace2,trace3,trace4,trace5]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7.3 Confusion Matrices for models "},{"metadata":{"trusted":false},"cell_type":"code","source":"lst    = [logit,logit_rus,decision_tree,knn,rfc,\n          gnb,svc_lin,svc_rbf,lgbm_c,xgc]\n\nlength = len(lst)\n\nmods   = ['Logistic Regression(Baseline_model)','Logistic Regression(Random Undersampling)',\n          'Decision Tree','KNN Classifier','Random Forest Classifier',\"Naive Bayes\",\n          'SVM Classifier Linear','SVM Classifier RBF', 'LGBM Classifier',\n          'XGBoost Classifier']\n\nfig = plt.figure(figsize=(13,15))\nfig.set_facecolor(\"#F3F3F3\")\nfor i,j,k in itertools.zip_longest(lst,range(length),mods) :\n    plt.subplot(4,3,j+1)\n    predictions = i.predict(test_X)\n    conf_matrix = confusion_matrix(predictions,test_Y)\n    sns.heatmap(conf_matrix,annot=True,fmt = \"d\",square = True,\n                xticklabels=[\"No Travel Booking\",\"Travel Booking\"],\n                yticklabels=[\"No Travel Booking\",\"Travel Booking\"],\n                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n    plt.title(k,color = \"b\")\n    plt.subplots_adjust(wspace = .3,hspace = .3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7.4 ROC-Curve for models "},{"metadata":{"trusted":false},"cell_type":"code","source":"lst    = [logit,logit_rus,decision_tree,knn,rfc,\n          gnb,svc_lin,svc_rbf,lgbm_c,xgc]\n\nlength = len(lst)\n\nmods   = ['Logistic Regression(Baseline_model)','Logistic Regression(Random Undersampling)',\n          'Decision Tree','KNN Classifier','Random Forest Classifier',\"Naive Bayes\",\n          'SVM Classifier Linear','SVM Classifier RBF', 'LGBM Classifier',\n          'XGBoost Classifier']\n\nplt.style.use(\"dark_background\")\nfig = plt.figure(figsize=(12,16))\nfig.set_facecolor(\"#F3F3F3\")\nfor i,j,k in itertools.zip_longest(lst,range(length),mods) :\n    qx = plt.subplot(4,3,j+1)\n    probabilities = i.predict_proba(test_X)\n    predictions   = i.predict(test_X)\n    fpr,tpr,thresholds = roc_curve(test_Y,probabilities[:,1])\n    plt.plot(fpr,tpr,linestyle = \"dotted\",\n             color = \"royalblue\",linewidth = 2,\n             label = \"AUC = \" + str(np.around(roc_auc_score(test_Y,predictions),3)))\n    plt.plot([0,1],[0,1],linestyle = \"dashed\",\n             color = \"orangered\",linewidth = 1.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7.5 Precision recall curves"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\n\n\nlst    = [logit,logit_rus,decision_tree,knn,rfc,\n          gnb,svc_lin,svc_rbf,lgbm_c,xgc]\n\nlength = len(lst)\n\nmods   = ['Logistic Regression(Baseline_model)','Logistic Regression(Random Undersampling)',\n          'Decision Tree','KNN Classifier','Random Forest Classifier',\"Naive Bayes\",\n          'SVM Classifier Linear','SVM Classifier RBF', 'LGBM Classifier',\n          'XGBoost Classifier']\n\nfig = plt.figure(figsize=(13,17))\nfig.set_facecolor(\"#F3F3F3\")\nfor i,j,k in itertools.zip_longest(lst,range(length),mods) :\n    \n    qx = plt.subplot(4,3,j+1)\n    probabilities = i.predict_proba(test_X)\n    predictions   = i.predict(test_X)\n    recall,precision,thresholds = precision_recall_curve(test_Y,probabilities[:,1])\n    plt.plot(recall,precision,linewidth = 1.5,\n             label = (\"avg_pcn : \" + \n                      str(np.around(average_precision_score(test_Y,predictions),3))))\n    plt.plot([0,1],[0,0],linestyle = \"dashed\")\n    plt.fill_between(recall,precision,alpha = .2)\n    plt.legend(loc = \"lower left\",\n               prop = {\"size\" : 10})\n    qx.set_facecolor(\"k\")\n    plt.grid(True,alpha = .15)\n    plt.title(k,color = \"b\")\n    plt.xlabel(\"recall\",fontsize =7)\n    plt.ylabel(\"precision\",fontsize =7)\n    plt.xlim([0.25,1])\n    plt.yticks(np.arange(0,1,.3))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8 Lift Analysis "},{"metadata":{},"cell_type":"markdown","source":"https://stackoverflow.com/questions/42699243/how-to-build-a-lift-chart-a-k-a-gains-chart-in-python"}],"metadata":{"kernelspec":{"display_name":"Pyspark 2.1","language":"python","name":"pyspark-custom-2.1"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.5"}},"nbformat":4,"nbformat_minor":4}